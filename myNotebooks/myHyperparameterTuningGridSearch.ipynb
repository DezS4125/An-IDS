{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c10b4d-cc49-41de-8684-d40d7c117fd5",
   "metadata": {
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1732623778797,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "c8c10b4d-cc49-41de-8684-d40d7c117fd5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce8a5a50-5f73-4e74-9333-d0a4bcd29c2d",
   "metadata": {
    "executionInfo": {
     "elapsed": 11891,
     "status": "ok",
     "timestamp": 1732623790993,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "ce8a5a50-5f73-4e74-9333-d0a4bcd29c2d"
   },
   "outputs": [],
   "source": [
    "import numpy as np  # for array\n",
    "import pandas as pd  # for csv files and dataframe\n",
    "import matplotlib.pyplot as plt  # for plotting\n",
    "import seaborn as sns  # plotting\n",
    "from scipy import stats\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle  # To load data int disk\n",
    "from prettytable import PrettyTable  # To print in tabular format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  # Standardizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder  # One hot Encoder\n",
    "from scipy.sparse import csr_matrix  # For sparse matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Different Models\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier  # LR\n",
    "from sklearn.svm import LinearSVC  # SVM\n",
    "from sklearn.tree import DecisionTreeClassifier  #DT\n",
    "from sklearn.ensemble import RandomForestClassifier  # RF\n",
    "import xgboost as xgb  #XGB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer  # Scoring functions\n",
    "from sklearn.metrics import auc, f1_score, roc_curve, roc_auc_score  # Scoring fns\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV  # Cross validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "PRsGys-Ba532",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17114,
     "status": "ok",
     "timestamp": 1732623944536,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "PRsGys-Ba532",
    "outputId": "4d2c4b64-e4fc-410f-bf53-a65c8b372c35"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# drive_path=\"drive/MyDrive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0c87f82-0b1d-4330-a90a-92d8b62da00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_path=\"/home/dezs/projects/myIDS/datasets/\"\n",
    "model_path=\"/home/dezs/projects/myIDS/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c2155f-9d84-4b0b-88e2-e9abfae7952f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "executionInfo": {
     "elapsed": 4767,
     "status": "error",
     "timestamp": 1732624082439,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "01c2155f-9d84-4b0b-88e2-e9abfae7952f",
    "outputId": "23484f6e-5f53-42e9-85a0-db003c6890b2"
   },
   "outputs": [],
   "source": [
    "file_path = drive_path+\"myDataset\"\n",
    "# Train and Test data\n",
    "x_train, y_train = pickle.load(open(file_path+'/final_super_small_oversampled_train.pkl', 'rb'))\n",
    "x_test, y_test = pickle.load(open(file_path+'/final_test.pkl', 'rb'))\n",
    "\n",
    "# Dictionaries\n",
    "saved_infos = pickle.load(open(file_path+'/saved_infos.pkl', 'rb'))\n",
    "mode_dict = pickle.load(open(file_path+'/mode_dict.pkl', 'rb'))\n",
    "\n",
    "# Standard scaler\n",
    "scaler = pickle.load(open(file_path+'/scaler.pkl', 'rb'))\n",
    "\n",
    "# Onehot encoders\n",
    "ohe_proto = pickle.load(open(file_path+'/ohe_proto.pkl', 'rb'))\n",
    "ohe_service = pickle.load(open(file_path+'/ohe_service.pkl', 'rb'))\n",
    "ohe_state = pickle.load(open(file_path+'/ohe_state.pkl', 'rb'))\n",
    "\n",
    "label_encoder = pickle.load(open(file_path+'/label_encoder.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95aa1597-287b-40fb-9f84-e393c6ee8aae",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1732623958845,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "95aa1597-287b-40fb-9f84-e393c6ee8aae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['analysis' 'backdoor' 'dos' 'exploits' 'fuzzers' 'generic' 'normal'\n",
      " 'reconnaissance' 'shellcode' 'worms']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "{'analysis': np.int64(0), 'backdoor': np.int64(1), 'dos': np.int64(2), 'exploits': np.int64(3), 'fuzzers': np.int64(4), 'generic': np.int64(5), 'normal': np.int64(6), 'reconnaissance': np.int64(7), 'shellcode': np.int64(8), 'worms': np.int64(9)}\n"
     ]
    }
   ],
   "source": [
    "class_labels = label_encoder.classes_\n",
    "print(class_labels)\n",
    "encoded_values = label_encoder.transform(['analysis', 'backdoor', 'dos', 'exploits', 'fuzzers', 'generic', 'normal', 'reconnaissance', 'shellcode', 'worms'])\n",
    "print(encoded_values)\n",
    "mapping = dict(zip(class_labels, encoded_values))\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbf2d92b-219b-4dec-8472-cbd98d45a70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617826, 48)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b915b8a-11ae-4702-8032-ce49f0711a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 197)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e8ac7-3e27-43f5-aa62-1cce3e24b19d",
   "metadata": {
    "id": "0b4e8ac7-3e27-43f5-aa62-1cce3e24b19d"
   },
   "source": [
    "## Pipeline functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0def3cd4-ebeb-4d3c-9733-297a391522d2",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1732623958845,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "0def3cd4-ebeb-4d3c-9733-297a391522d2"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "# Data Cleaning\n",
    "#------------------------------------------------------------------------------------------\n",
    "def clean_data(data):\n",
    "    '''\n",
    "    Cleans given raw data. Performs various cleaning, removes Null and wrong values.\n",
    "    Check for columns datatype and fix them.\n",
    "    '''\n",
    "    numerical_col = data.select_dtypes(include=np.number).columns  # All the numerical columns list\n",
    "    categorical_col = data.select_dtypes(exclude=np.number).columns  # All the categorical columns list\n",
    "\n",
    "    # Cleaning the data\n",
    "    for col in data.columns:\n",
    "        val = mode_dict[col]  # Mode value of the column in train data\n",
    "        data[col] = data[col].fillna(value=val)\n",
    "        data[col] = data[col].replace(' ', value=val)\n",
    "        data[col] = data[col].apply(lambda x:\"none\" if x==\"-\" else x)\n",
    "\n",
    "        # Fixing binary columns\n",
    "        if col in saved_infos['binary_col']:\n",
    "            data[col] = np.where(data[col]>1, val, data[col])\n",
    "\n",
    "    # Fixing datatype of columns\n",
    "    bad_dtypes = list(set(categorical_col) - set(saved_infos['cat_col']))\n",
    "    for bad_col in bad_dtypes:\n",
    "        data[col] = data[col].astype(float)\n",
    "\n",
    "    return data\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# Feature Engineering: Apply log1p\n",
    "#------------------------------------------------------------------------------------------\n",
    "# def apply_log1p(data):\n",
    "#     '''\n",
    "#     Performs FE on the data. Apply log1p on the specified columns create new column and remove those original columns.\n",
    "#     '''\n",
    "#     for col in saved_infos['log1p_col']:\n",
    "#         new_col = col + '_log1p'  # New col name\n",
    "#         data[new_col] = data[col].apply(np.log1p)  # Creating new column on transformed data\n",
    "#         data.drop(col, axis=1, inplace=True)  # Removing old columns\n",
    "#     return data\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# Standardizing: Mean centering an d varience scaling\n",
    "#------------------------------------------------------------------------------------------\n",
    "def standardize(data):\n",
    "    '''\n",
    "    Stanardize the given data. Performs mean centering and varience scaling.\n",
    "    Using stanardscaler object trained on train data.\n",
    "    '''\n",
    "    data[saved_infos['num_col']] = scaler.transform(data[saved_infos['num_col']])\n",
    "    return data\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# Onehot encoding of categorical columns\n",
    "#------------------------------------------------------------------------------------------\n",
    "def ohencoding(data):\n",
    "    '''\n",
    "    Onehot encoding the categoricla columns.\n",
    "    Add the ohe columns with the data and removes categorical columns.\n",
    "    Using Onehotencoder objects trained on train data.\n",
    "    '''\n",
    "    # Onehot encoding cat col using onehotencoder objects\n",
    "    X = ohe_service.transform(data['service'].values.reshape(-1, 1))\n",
    "    Xm = ohe_proto.transform(data['proto'].values.reshape(-1, 1))\n",
    "    Xmm = ohe_state.transform(data['state'].values.reshape(-1, 1))\n",
    "\n",
    "    # Adding encoding data to original data\n",
    "    data = pd.concat([data,\n",
    "                      pd.DataFrame(Xm.toarray(), columns=['proto_'+i for i in ohe_proto.categories_[0]]),\n",
    "                      pd.DataFrame(X.toarray(), columns=['service_'+i for i in ohe_service.categories_[0]]),\n",
    "                      pd.DataFrame(Xmm.toarray(), columns=['state_'+i for i in ohe_state.categories_[0]])],\n",
    "                      axis=1)\n",
    "\n",
    "    # Removing cat columns\n",
    "    data.drop(['proto', 'service', 'state'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4edd3203-a625-4717-a236-67ff3198d6bd",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1732623958845,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "4edd3203-a625-4717-a236-67ff3198d6bd"
   },
   "outputs": [],
   "source": [
    "def labelcoding(data):\n",
    "    data= label_encoder.transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d5c6266-5bcf-47bc-8114-06750d6132d3",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1732623958845,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "3d5c6266-5bcf-47bc-8114-06750d6132d3"
   },
   "outputs": [],
   "source": [
    "def get_final_data(data, saved_infos=saved_infos, mode_dict=mode_dict):\n",
    "    '''\n",
    "    This functions takes raw input and convert that to model required output.\n",
    "    '''\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data.columns = saved_infos['columns']\n",
    "\n",
    "    data['network_bytes'] = data['dbytes'] + data['sbytes']\n",
    "\n",
    "    dropable_col = saved_infos['to_drop'] + saved_infos['corr_col']\n",
    "    data.drop(columns=dropable_col, inplace=True)\n",
    "\n",
    "    data = clean_data(data)\n",
    "    # data = apply_log1p(data)\n",
    "    data = standardize(data)\n",
    "    data = ohencoding(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02b6dbc4-d547-4b5e-87c4-13e35abefd30",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1732623958845,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "02b6dbc4-d547-4b5e-87c4-13e35abefd30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['dhcp', 'dns', 'ftp', 'ftp-data', 'http', 'irc', 'none', 'pop3',\n",
       "        'radius', 'smtp', 'snmp', 'ssh', 'ssl'], dtype=object)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_service.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "633d8e21-4d2e-42e0-abd3-655d518dcb3f",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1732623958845,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "633d8e21-4d2e-42e0-abd3-655d518dcb3f"
   },
   "outputs": [],
   "source": [
    "# Using pipeline to prepare test data\n",
    "x_test = get_final_data(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4cda83d-a2c6-43d0-9b60-b37fb8728e4e",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1732623958845,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "b4cda83d-a2c6-43d0-9b60-b37fb8728e4e"
   },
   "outputs": [],
   "source": [
    "y_test=y_test.fillna(value=\"normal\").apply(lambda x:x.strip().lower())\n",
    "y_test = y_test.replace('backdoors','backdoor', regex=True).apply(lambda x: x.strip().lower())\n",
    "y_test= labelcoding(y_test)\n",
    "y_test = pd.DataFrame(y_test,columns=['attack_cat',],)\n",
    "y_test=y_test['attack_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0535cc6f-d186-4566-aa47-4524c712ec81",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1732623958846,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "0535cc6f-d186-4566-aa47-4524c712ec81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 197), (1000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77aa4627-9f00-466d-be0f-c432da42c48d",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1732623958846,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "77aa4627-9f00-466d-be0f-c432da42c48d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((617826, 197), (617826,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96f62f5f-0a40-41d0-975e-d004fb2943a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns only in train: set()\n",
      "Columns only in test: set()\n"
     ]
    }
   ],
   "source": [
    "train_columns = set(x_train.columns)\n",
    "test_columns = set(x_test.columns)\n",
    "\n",
    "# Find columns only in train\n",
    "train_only_columns = train_columns - test_columns\n",
    "\n",
    "# Find columns only in test\n",
    "test_only_columns = test_columns - train_columns\n",
    "\n",
    "print(\"Columns only in train:\", train_only_columns)\n",
    "print(\"Columns only in test:\", test_only_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a95ddc1-c7a4-4d82-8a2c-8f4a8d63fd7a",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1732623958846,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "0a95ddc1-c7a4-4d82-8a2c-8f4a8d63fd7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(x_train.columns == x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169bfbc1-ac88-428b-b2be-9a4724783c8f",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1732623958846,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "169bfbc1-ac88-428b-b2be-9a4724783c8f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b079cbef-7098-4559-8983-b9e697f49739",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1732623958846,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "b079cbef-7098-4559-8983-b9e697f49739"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "def encode_attack_non_attack(df):\n",
    "    #something broke, so i'm doing this, i'm tired\n",
    "    df=pd.DataFrame(df)\n",
    "    replace_values = [9, 8, 7, 5, 4, 3, 2, 1, 0]\n",
    "    new_df = df.replace(replace_values, 1).replace(6, 0)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "# def calculate_far(y_true, y_pred):\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "#     far = fp / (fp + tn)\n",
    "#     return 0\n",
    "\n",
    "# def false_alarm_rate(y_true, y_pred):\n",
    "#     \"\"\"\n",
    "#     This function will return False Alarm Rate for given true and predicted values.\n",
    "#     False Alarm Rate is average of False Negetive Rate and False Positive Rate\n",
    "#     \"\"\"\n",
    "#     # return calculate_far(y_true, y_pred)\n",
    "#     y_true=encode_attack_non_attack(y_true)\n",
    "#     y_pred = encode_attack_non_attack(y_pred)\n",
    "\n",
    "#     c_matrix=confusion_matrix(y_true, y_pred)\n",
    "#     tn, fp, fn, tp = c_matrix.ravel()\n",
    "\n",
    "#     labels= ['non-attack', 'attack']\n",
    "#     plt.figure(figsize=(8, 6))  # Adjust figure size as needed\n",
    "#     sns.heatmap(c_matrix, annot=True, cmap='Blues', fmt='d',xticklabels=labels, yticklabels=labels)  # Customize colors and format\n",
    "#     plt.xlabel('Predicted Label')\n",
    "#     plt.ylabel('True Label')\n",
    "#     plt.title(f'Confusion Matrix for General Attack Detection')\n",
    "#     plt.show()\n",
    "#     FPR = fp / (fp + tn)  # False positive rate\n",
    "#     FNR = fn / (fn + tp)  # False negetive rate\n",
    "#     return (FPR+FNR)/2  # False alarm rate\n",
    "\n",
    "\n",
    "def evaluate_result(y_true, y_pred, model_name):\n",
    "    # far=false_alarm_rate(y_true, y_pred)\n",
    "    # test_f1 = f1_score(y_test, y_test_pred, average=None)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred,average='weighted')\n",
    "\n",
    "    # cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n",
    "\n",
    "    x = PrettyTable()\n",
    "    x.field_names = [ 'Accuracy','Precision','Recall','F1']\n",
    "    x.add_row([accuracy,precision,recall,f1])\n",
    "    print(x)\n",
    "\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Create a heatmap with clear labels and annotations\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size as needed\n",
    "    sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='d')  # Customize colors and format\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.show()\n",
    "    # cm_display.plot()\n",
    "    # plt.show()\n",
    "\n",
    "    # Returning scores\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2ac05bb-cd24-4ef4-ba77-9d53ac2436a9",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1732623958846,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "f2ac05bb-cd24-4ef4-ba77-9d53ac2436a9"
   },
   "outputs": [],
   "source": [
    "old_x_train=x_train\n",
    "old_y_train=y_train\n",
    "old_x_test=x_test\n",
    "old_y_test=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78b9b56e-64a9-4976-bf16-d65c1dd3c239",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1732623958846,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "78b9b56e-64a9-4976-bf16-d65c1dd3c239"
   },
   "outputs": [],
   "source": [
    "# old_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bf0bb36-7ff2-411a-a4f2-c5ef0c59083c",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1732623958846,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "1bf0bb36-7ff2-411a-a4f2-c5ef0c59083c"
   },
   "outputs": [],
   "source": [
    "line_count=1000\n",
    "\n",
    "# x_train=old_x_train.head(line_count)\n",
    "# y_train=old_y_train.head(line_count)\n",
    "x_test=old_x_test.head(line_count)\n",
    "y_test=old_y_test.head(line_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8be74f2-ac9c-43eb-a510-8d99b7c1bb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 197)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7300ddd4-3b4c-44ea-9093-74383033b776",
   "metadata": {
    "id": "7300ddd4-3b4c-44ea-9093-74383033b776"
   },
   "source": [
    "## Long term short term neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92b3e92d-182b-4af7-af34-21f71094b26d",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1732623958846,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "92b3e92d-182b-4af7-af34-21f71094b26d"
   },
   "outputs": [],
   "source": [
    "# sequence_length = 300\n",
    "# batch_size = 128\n",
    "\n",
    "# X_train_seq = pad_sequences( x_train, maxlen = sequence_length)\n",
    "# X_test_seq = pad_sequences( x_test, maxlen = sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31a54a0c-8ba6-41c5-8099-b2b8b6ad1888",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1732623958846,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "31a54a0c-8ba6-41c5-8099-b2b8b6ad1888"
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(e)\n",
    "\n",
    "# model.add(LSTM( 128 , dropout = 0.25, recurrent_dropout = 0.25))\n",
    "\n",
    "# model.add(Dense(1, activation = 'sigmoid' ))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile( optimizer = \"adam\" , loss = 'binary_crossentropy' , metrics = ['accuracy'] )\n",
    "\n",
    "# early_stopper = EarlyStopping( monitor = 'val_acc' , min_delta = 0.0005, patience = 3 )\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau( monitor = 'val_loss' , patience = 2 , cooldown = 0)\n",
    "\n",
    "# callbacks = [ reduce_lr , early_stopper]\n",
    "\n",
    "# train_history = model.fit( X_train_seq , y_train , batch_size = batch_size, epochs = 5,validation_split = 0.1 , verbose = 1 , callbacks = callbacks)\n",
    "\n",
    "# score = model.evaluate( X_test_seq , y_test , batch_size = batch_size)\n",
    "\n",
    "# print( \"Accuracy: {:0.4}\".format( score[1] ))\n",
    "\n",
    "# print( \"Loss:\", score[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8776d51c-4555-49ba-abfe-fd693e196abd",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1732623958846,
     "user": {
      "displayName": "Khang Lam Hoang",
      "userId": "02732529430571730404"
     },
     "user_tz": -420
    },
    "id": "8776d51c-4555-49ba-abfe-fd693e196abd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    100\n",
       "3    100\n",
       "5    100\n",
       "4    100\n",
       "7    100\n",
       "2    100\n",
       "0    100\n",
       "1    100\n",
       "8    100\n",
       "9    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2037ff2-c743-4e0e-b073-bfbc312c146c",
   "metadata": {},
   "source": [
    "## No parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0edb1a-7919-4c32-843c-cff5ddf5aff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3cef81b-95e0-41db-a1a4-cdba79b9c28f",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e63bd9-f162-4bfb-8db2-2279b3736ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report,precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0afab-8dc1-4a38-ac4f-a1cfe35b00ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28c71c1f-b665-4672-9794-d26860c7ddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Best score: 0.5980000000000001\n"
     ]
    }
   ],
   "source": [
    "##SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], \n",
    "              'gamma': [0.1, 1, 10], \n",
    "              'kernel': ['rbf', 'poly', 'linear']}\n",
    "\n",
    "svm_model = SVC()\n",
    "\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5,n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fb63360-9253-4552-b507-5a20463d0098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'entropy', 'max_depth': 9, 'max_leaf_nodes': 25, 'min_samples_split': 2}\n",
      "Best score: 0.641\n"
     ]
    }
   ],
   "source": [
    "## DT\n",
    "parameters = {'criterion':['gini','entropy'],\n",
    "              'max_depth':np.arange(1,21).tolist()[0::2],\n",
    "              'min_samples_split':np.arange(2,11).tolist()[0::2],\n",
    "              'max_leaf_nodes':np.arange(3,26).tolist()[0::2]}\n",
    "\n",
    "# create an instance of the grid search object\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "# conduct grid search over the parameter space\n",
    "grid_search.fit(x_train,y_train)\n",
    "\n",
    "# show best parameter configuration found for classifier\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30b00568-3928-45c2-bbc9-4a0057d5bffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'max_features': None, 'max_leaf_nodes': 20, 'n_estimators': 25}\n",
      "Best score: 0.6539999999999999\n"
     ]
    }
   ],
   "source": [
    "## Random Forest\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 300, 400, 500], \n",
    "    'max_features': ['sqrt', 'log2', None], \n",
    "    'max_depth': [5, 10, 20], \n",
    "    'max_leaf_nodes': [5, 10, 20], \n",
    "} \n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=5, n_jobs=-1) \n",
    "grid_search.fit(x_train, y_train) \n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2101d-d632-42a7-a495-2a86290139c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_grid = {\n",
    "        'n_estimators': [200, 300, 400, 500], \n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.02, objective='binary:logistic', nthread=1)\n",
    "\n",
    "grid_search = GridSearchCV(xgb, param_grid=param_grid, cv=5, n_jobs=-1) \n",
    "grid_search.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ee3534f-abde-4860-af6c-fa05a5a494f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.6, 'gamma': 1.5, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0}\n",
      "Best score: 0.708\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
